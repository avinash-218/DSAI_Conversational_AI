{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBl5TBxtCT7Y"
   },
   "source": [
    "# Disclaimer:\n",
    "\n",
    "DeepSphere.AI developed these\n",
    "materials based on its team’s expertise\n",
    "and technical infrastructure, and we\n",
    "are sharing these materials strictly for\n",
    "learning and research. These learning\n",
    "resources may not work on other learning\n",
    "infrastructures and DeepSphere.AI\n",
    "advises the learners to use these materials\n",
    "at their own risk. As needed, we will be\n",
    "changing these materials without any\n",
    "notification and we have full ownership\n",
    "and accountability to make any change\n",
    "to these materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABzLWUmj3NUZ"
   },
   "source": [
    "# Import Libraries and Set Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1837,
     "status": "ok",
     "timestamp": 1646149229348,
     "user": {
      "displayName": "Avinash R",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15255253214987421206"
     },
     "user_tz": -330
    },
    "id": "VtSN44pE28y7"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2F_uuBZ73SP"
   },
   "source": [
    "# Class KnowledgeGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1646149229900,
     "user": {
      "displayName": "Avinash R",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15255253214987421206"
     },
     "user_tz": -330
    },
    "id": "MnYm7IUI76UB"
   },
   "outputs": [],
   "source": [
    "class KnowledgeGraph:\n",
    "  def __init__(self, vAR_candidate_sentences):\n",
    "    #constructor\n",
    "    #vAR_candidate_sentences - csv input file\n",
    "    self.vAR_nlp = spacy.load('en_core_web_sm') #load spacy\n",
    "    self.vAR_candidate_sentences = vAR_candidate_sentences\n",
    "    self.vAR_entity_pairs = []\n",
    "    self.vAR_kg_df = None\n",
    "    self.vAR_relations = None\n",
    "\n",
    "  def display_samples(self):\n",
    "    #method to display samples\n",
    "    print(self.vAR_candidate_sentences['sentence'].sample(5))\n",
    "\n",
    "  def tokenize(self, vAR_doc):\n",
    "    #method to tokenize the input vAR_doc\n",
    "    vAR_doc = self.vAR_nlp(\"the drawdown process is governed by astm standard d823\")\n",
    "\n",
    "    for tok in vAR_doc:\n",
    "      print(tok.text, \"...\", tok.dep_)\n",
    "\n",
    "  def get_entities(self, vAR_sent):\n",
    "    #method to get entities from input sentence\n",
    "    ## chunk 1\n",
    "    vAR_ent1 = \"\"\n",
    "    vAR_ent2 = \"\"\n",
    "\n",
    "    vAR_prv_tok_dep = \"\"    # dependency tag of previous token in the sentence\n",
    "    vAR_prv_tok_text = \"\"   # previous token in the sentence\n",
    "\n",
    "    vAR_prefix = \"\"\n",
    "    vAR_modifier = \"\"\n",
    "\n",
    "    #############################################################\n",
    "    \n",
    "    for tok in self.vAR_nlp(vAR_sent):\n",
    "      ## chunk 2\n",
    "      # if token is a punctuation mark then move on to the next token\n",
    "      if tok.dep_ != \"punct\":\n",
    "        # check: token is a compound word or not\n",
    "        if tok.dep_ == \"compound\":\n",
    "          vAR_prefix = tok.text\n",
    "          # if the previous word was also a 'compound' then add the current word to it\n",
    "          if vAR_prv_tok_dep == \"compound\":\n",
    "            vAR_prefix = vAR_prv_tok_text + \" \"+ tok.text\n",
    "        \n",
    "        # check: token is a modifier or not\n",
    "        if tok.dep_.endswith(\"mod\") == True:\n",
    "          vAR_modifier = tok.text\n",
    "          # if the previous word was also a 'compound' then add the current word to it\n",
    "          if vAR_prv_tok_dep == \"compound\":\n",
    "            vAR_modifier = vAR_prv_tok_text + \" \"+ tok.text\n",
    "        \n",
    "        ## chunk 3\n",
    "        if tok.dep_.find(\"subj\") == True:\n",
    "          vAR_ent1 = vAR_modifier +\" \"+ vAR_prefix + \" \"+ tok.text\n",
    "          vAR_prefix = \"\"\n",
    "          vAR_modifier = \"\"\n",
    "          vAR_prv_tok_dep = \"\"\n",
    "          vAR_prv_tok_text = \"\"      \n",
    "\n",
    "        ## chunk 4\n",
    "        if tok.dep_.find(\"obj\") == True:\n",
    "          vAR_ent2 = vAR_modifier +\" \"+ vAR_prefix +\" \"+ tok.text\n",
    "          \n",
    "        ## chunk 5  \n",
    "        # update variables\n",
    "        vAR_prv_tok_dep = tok.dep_\n",
    "        vAR_prv_tok_text = tok.text\n",
    "    #############################################################\n",
    "\n",
    "    return [vAR_ent1.strip(), vAR_ent2.strip()]\n",
    "\n",
    "  def find_entity_pairs(self):\n",
    "    #method to find entity pairs from sentence\n",
    "    for i in tqdm(self.vAR_candidate_sentences[\"sentence\"]):\n",
    "      self.vAR_entity_pairs.append(self.get_entities(i))\n",
    "\n",
    "  def display_entity_pairs(self):\n",
    "    #method to display entity pairs\n",
    "    print(self.vAR_entity_pairs[10:20])\n",
    "\n",
    "  def get_relation(self, vAR_sent):\n",
    "    #method to get rela\n",
    "    doc = self.vAR_nlp(vAR_sent)\n",
    "\n",
    "    # Matcher class object \n",
    "    vAR_matcher = Matcher(self.vAR_nlp.vocab)\n",
    "\n",
    "    #define the pattern \n",
    "    vAR_pattern = [{'DEP':'ROOT'}, \n",
    "              {'DEP':'prep','OP':\"?\"},\n",
    "              {'DEP':'agent','OP':\"?\"},  \n",
    "              {'POS':'ADJ','OP':\"?\"}] \n",
    "\n",
    "    vAR_matcher.add(\"matching_1\", [vAR_pattern], on_match=None)\n",
    "    matches = vAR_matcher(doc)\n",
    "    k = len(matches) - 1\n",
    "    vAR_span = doc[matches[k][1]:matches[k][2]] \n",
    "    return(vAR_span.text)\n",
    "\n",
    "  def display_relations(self):\n",
    "    #method to display relations\n",
    "    self.vAR_relations = [self.get_relation(i) for i in tqdm(self.vAR_candidate_sentences['sentence'])]\n",
    "    print(pd.Series(self.vAR_relations).value_counts()[:50])\n",
    "\n",
    "  def extract_subject_and_object(self):\n",
    "    # extract subject and object from entity pairs\n",
    "    vAR_source = [i[0] for i in self.vAR_entity_pairs]\n",
    "    # extract object\n",
    "    vAR_target = [i[1] for i in self.vAR_entity_pairs]\n",
    "\n",
    "    self.vAR_kg_df = pd.DataFrame({'source':vAR_source, 'target':vAR_target, 'edge':self.vAR_relations})\n",
    "\n",
    "  def plot_entire_knowledge_graph(self):\n",
    "    #method to plot entire knowledge graph\n",
    "    G = nx.from_pandas_edgelist(self.vAR_kg_df, \"source\", \"target\", edge_attr=True, create_using = nx.MultiDiGraph())\n",
    "    plt.figure(figsize=(12,12))\n",
    "\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap = plt.cm.Blues, pos = pos)\n",
    "    plt.show()\n",
    "\n",
    "  def plot_graph(self,var):\n",
    "    #method to plot graph based on input\n",
    "    G = nx.from_pandas_edgelist(self.vAR_kg_df[self.vAR_kg_df['edge']==var], \"source\", \"target\", edge_attr=True, create_using = nx.MultiDiGraph())\n",
    "    plt.figure(figsize=(12,12))\n",
    "    pos = nx.spring_layout(G, k = 0.5) # k regulates the distance between nodes\n",
    "    nx.draw(G, with_labels=True, node_color='skyblue', node_size=1500, edge_cmap = plt.cm.Blues, pos = pos)\n",
    "    plt.show()\n",
    "    \n",
    "  def RUN_ALL(self):\n",
    "    self.display_samples()\n",
    "    self.tokenize(\"the drawdown process is governed by astm standard d823\")#example\n",
    "    self.tokenize(\"Nagal won the first set.\")#example\n",
    "    self.get_entities(\"the film had 200 patents\")#example\n",
    "    self.tokenize(\"the drawdown process is governed by astm standard d823\")#example\n",
    "    self.find_entity_pairs()\n",
    "    self.display_entity_pairs()\n",
    "    self.get_relation(\"John completed the task\")#example\n",
    "    self.display_relations()\n",
    "    self.extract_subject_and_object()\n",
    "    self.plot_entire_knowledge_graph()\n",
    "    self.plot_graph(\"composed by\")#example\n",
    "    self.plot_graph(\"written by\")#example\n",
    "    self.plot_graph(\"released in\")#example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6OX7eIw3dBR"
   },
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 961,
     "status": "ok",
     "timestamp": 1646149230858,
     "user": {
      "displayName": "Avinash R",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15255253214987421206"
     },
     "user_tz": -330
    },
    "id": "m7OelNz128y9",
    "outputId": "0f488557-443c-4386-c0c3-58b016d6659a"
   },
   "outputs": [],
   "source": [
    "vAR_candidate_sentences = pd.read_csv(\"../Utility/DSAI_Wiki_Sentences_V2.csv\")\n",
    "vAR_knowledge_graph_object = KnowledgeGraph(vAR_candidate_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jliAIav58vn4"
   },
   "source": [
    "# Create Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2003,
     "status": "ok",
     "timestamp": 1646149232856,
     "user": {
      "displayName": "Avinash R",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15255253214987421206"
     },
     "user_tz": -330
    },
    "id": "-ELOdQqP8xDP",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                              | 15/4318 [00:00<00:31, 137.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4110                                                           it is distributed by dreamworks.\n",
      "1543    kannada actor rajkumar began working with veeranna and later became an important actor.\n",
      "417                                                      and he being remained as house arrest.\n",
      "3804                               fukunaga was announced as boyle's replacement a month later.\n",
      "1507                                                      some of the prominent ones include:\\n\n",
      "Name: sentence, dtype: object\n",
      "the ... det\n",
      "drawdown ... compound\n",
      "process ... nsubjpass\n",
      "is ... auxpass\n",
      "governed ... ROOT\n",
      "by ... agent\n",
      "astm ... compound\n",
      "standard ... pobj\n",
      "d823 ... punct\n",
      "the ... det\n",
      "drawdown ... compound\n",
      "process ... nsubjpass\n",
      "is ... auxpass\n",
      "governed ... ROOT\n",
      "by ... agent\n",
      "astm ... compound\n",
      "standard ... pobj\n",
      "d823 ... punct\n",
      "the ... det\n",
      "drawdown ... compound\n",
      "process ... nsubjpass\n",
      "is ... auxpass\n",
      "governed ... ROOT\n",
      "by ... agent\n",
      "astm ... compound\n",
      "standard ... pobj\n",
      "d823 ... punct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4318/4318 [01:15<00:00, 56.91it/s]\n",
      "  0%|▎                                                                              | 16/4318 [00:00<00:28, 150.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['we', 'tests'], ['m', 'international sales rights'], ['canadian musician robbie robertson', 'soundtrack'], ['it', 'original music tracks'], ['it', 'reviewed  franchise'], ['she', 'accidentally  mystique'], ['military  forces', 'arrest'], ['train', 'vuk'], ['kota eberhardt', 'telepath selene gallio'], ['singer', 'sequel']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████▍ | 4232/4318 [00:56<00:06, 13.11it/s]"
     ]
    }
   ],
   "source": [
    "vAR_knowledge_graph_object = KnowledgeGraph(vAR_candidate_sentences)\n",
    "vAR_knowledge_graph_object.RUN_ALL()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RKp_CLZCInA"
   },
   "source": [
    "# Copyright Notice:\n",
    "\n",
    "Local and international copyright laws protect\n",
    "this material. Repurposing or reproducing\n",
    "this material without written approval from\n",
    "DeepSphere.AI violates the law.\n",
    "\n",
    "(c) DeepSphere.AI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HBl5TBxtCT7Y",
    "o2alyw5z3VnZ",
    "ABzLWUmj3NUZ",
    "O2F_uuBZ73SP",
    "Y6OX7eIw3dBR",
    "jliAIav58vn4",
    "wCdPvCW_3ysE",
    "0RyEZB2x4OMH",
    "NxWAlyDx4RvQ",
    "C2hFLcyG7naO",
    "Sv5rq2V3GSF6",
    "KIXVpD3J7unX",
    "3RKp_CLZCInA"
   ],
   "name": "Knowledge graph.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
