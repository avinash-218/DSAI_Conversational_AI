{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBl5TBxtCT7Y"
   },
   "source": [
    "# Disclaimer:\n",
    "\n",
    "DeepSphere.AI developed these\n",
    "materials based on its teamâ€™s expertise\n",
    "and technical infrastructure, and we\n",
    "are sharing these materials strictly for\n",
    "learning and research. These learning\n",
    "resources may not work on other learning\n",
    "infrastructures and DeepSphere.AI\n",
    "advises the learners to use these materials\n",
    "at their own risk. As needed, we will be\n",
    "changing these materials without any\n",
    "notification and we have full ownership\n",
    "and accountability to make any change\n",
    "to these materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABzLWUmj3NUZ"
   },
   "source": [
    "# Import Libraries and Set Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1837,
     "status": "ok",
     "timestamp": 1646149229348,
     "user": {
      "displayName": "Avinash R",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15255253214987421206"
     },
     "user_tz": -330
    },
    "id": "VtSN44pE28y7"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'click.exceptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m displacy\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Matcher \n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\__init__.py:15\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m info  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglossary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explain  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\cli\\__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwasabi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m msg\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m app, setup_cli  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# These are the actual functions, NOT the wrapped CLI commands. The CLI commands\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# are registered automatically and won't have to be imported here.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\cli\\_util.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrsly\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhashlib\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyper\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclick\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoSuchOption\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclick\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_arg_string\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\typer\\__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Typer, build great CLIs. Easy to code. Based on Python type hints.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.3.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclick\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Abort \u001b[38;5;28;01mas\u001b[39;00m Abort\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclick\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BadParameter \u001b[38;5;28;01mas\u001b[39;00m BadParameter\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclick\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Exit \u001b[38;5;28;01mas\u001b[39;00m Exit\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'click.exceptions'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2F_uuBZ73SP"
   },
   "source": [
    "# Class KnowledgeGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1646149229900,
     "user": {
      "displayName": "Avinash R",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15255253214987421206"
     },
     "user_tz": -330
    },
    "id": "MnYm7IUI76UB"
   },
   "outputs": [],
   "source": [
    "class KnowledgeGraph:\n",
    "  def __init__(self, vAR_candidate_sentences):\n",
    "    #constructor\n",
    "    #vAR_candidate_sentences - csv input file\n",
    "    self.vAR_nlp = spacy.load('en_core_web_sm') #load spacy\n",
    "    self.vAR_candidate_sentences = vAR_candidate_sentences\n",
    "    self.vAR_entity_pairs = []\n",
    "    self.vAR_kg_df = None\n",
    "    self.vAR_relations = None\n",
    "\n",
    "  def get_entities(self, vAR_sent):\n",
    "    #method to get entities from input sentence\n",
    "\n",
    "    #subject, object, dependency, tag of previous token in the sentence, previous token in the sentence\n",
    "    vAR_ent1 = vAR_ent2 =vAR_prv_tok_dep =vAR_prv_tok_text =vAR_prefix =vAR_modifier = \"\"\n",
    "\n",
    "    for tok in self.vAR_nlp(vAR_sent): #tokenize\n",
    "        \n",
    "      if (tok.dep_ == \"punct\"):#if token is punctuation mark then skip it\n",
    "        continue\n",
    "      else:\n",
    "        #compound+compound\n",
    "        if (tok.dep_ == \"compound\"):#if token is a compound word\n",
    "          vAR_prefix = tok.text\n",
    "          if(vAR_prv_tok_dep == \"compound\"):#previous word is 'compound'\n",
    "            vAR_prefix = vAR_prv_tok_text + \" \"+ tok.text\n",
    "        \n",
    "        #compound+modifier\n",
    "        if(tok.dep_.endswith(\"mod\") == True):#if token is a modifier\n",
    "          vAR_modifier = tok.text\n",
    "          if(vAR_prv_tok_dep == \"compound\"):#previous word is 'compound'\n",
    "            vAR_modifier = vAR_prv_tok_text + \" \"+ tok.text\n",
    "        \n",
    "        if(tok.dep_.find(\"subj\") == True):#subject\n",
    "          vAR_ent1 = vAR_modifier +\" \"+ vAR_prefix + \" \"+ tok.text\n",
    "          vAR_prefix =vAR_modifier =vAR_prv_tok_dep =vAR_prv_tok_text = \"\"      \n",
    "\n",
    "        if(tok.dep_.find(\"obj\") == True):#object\n",
    "          vAR_ent2 = vAR_modifier +\" \"+ vAR_prefix +\" \"+ tok.text\n",
    "          \n",
    "        # update variables previous toke_dep and tok_text\n",
    "        vAR_prv_tok_dep = tok.dep_\n",
    "        vAR_prv_tok_text = tok.text\n",
    "\n",
    "    return [vAR_ent1.strip(), vAR_ent2.strip()]\n",
    "\n",
    "  def find_entity_pairs(self):\n",
    "    #method to find entity pairs from sentence\n",
    "    for i in tqdm(self.vAR_candidate_sentences[\"sentence\"]):\n",
    "      self.vAR_entity_pairs.append(self.get_entities(i))\n",
    "\n",
    "  def get_relation(self, vAR_sent):\n",
    "    #method to get relations\n",
    "    doc = self.vAR_nlp(vAR_sent)\n",
    "\n",
    "    # Matcher class object \n",
    "    vAR_matcher = Matcher(self.vAR_nlp.vocab)\n",
    "\n",
    "    #define the pattern \n",
    "    #root preposition agent adjective\n",
    "    vAR_pattern = [{'DEP':'ROOT'},{'DEP':'prep','OP':\"?\"},{'DEP':'agent','OP':\"?\"},{'POS':'ADJ','OP':\"?\"}]\n",
    "\n",
    "    vAR_matcher.add(\"matching_1\", [vAR_pattern], on_match=None)\n",
    "    matches = vAR_matcher(doc)\n",
    "    k = len(matches) - 1\n",
    "    vAR_span = doc[matches[k][1]:matches[k][2]] \n",
    "    return(vAR_span.text)\n",
    "\n",
    "  def find_relations(self):\n",
    "    #method to display relations\n",
    "    self.vAR_relations = []\n",
    "    for i in tqdm(self.vAR_candidate_sentences['sentence']):\n",
    "        self.vAR_relations.append(self.get_relation(i))\n",
    "\n",
    "  def extract_subject_and_object(self):\n",
    "    # extract subject and object from entity pairs\n",
    "    vAR_source = []\n",
    "    vAR_target = []\n",
    "    \n",
    "    for i in self.vAR_entity_pairs:\n",
    "        vAR_source.append(i[0])\n",
    "        vAR_target.append(i[1])\n",
    "\n",
    "    self.vAR_kg_df = pd.DataFrame({'source':vAR_source, 'target':vAR_target, 'edge':self.vAR_relations})\n",
    "\n",
    "  def plot_graph(self,var):\n",
    "    #method to plot graph based on input\n",
    "    G = nx.from_pandas_edgelist(self.vAR_kg_df[self.vAR_kg_df['edge']==var], \"source\", \"target\", edge_attr=True, create_using = nx.MultiDiGraph())\n",
    "    plt.figure(figsize=(12,12))\n",
    "    pos = nx.spring_layout(G, k = 0.5) # k regulates the distance between nodes\n",
    "    nx.draw(G, with_labels=True, node_size=1500, edge_cmap = plt.cm.Blues, pos = pos)\n",
    "    plt.show()\n",
    "    \n",
    "  def RUN_ALL(self):\n",
    "    self.find_entity_pairs()\n",
    "    self.find_relations()\n",
    "    self.extract_subject_and_object()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6OX7eIw3dBR"
   },
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 961,
     "status": "ok",
     "timestamp": 1646149230858,
     "user": {
      "displayName": "Avinash R",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15255253214987421206"
     },
     "user_tz": -330
    },
    "id": "m7OelNz128y9",
    "outputId": "0f488557-443c-4386-c0c3-58b016d6659a"
   },
   "outputs": [],
   "source": [
    "vAR_candidate_sentences = pd.read_csv(\"../Utility/DSAI_Wiki_Sentences_V2.csv\",encoding='cp1252')\n",
    "vAR_knowledge_graph_object = KnowledgeGraph(vAR_candidate_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jliAIav58vn4"
   },
   "source": [
    "# Create Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2003,
     "status": "ok",
     "timestamp": 1646149232856,
     "user": {
      "displayName": "Avinash R",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15255253214987421206"
     },
     "user_tz": -330
    },
    "id": "-ELOdQqP8xDP"
   },
   "outputs": [],
   "source": [
    "vAR_knowledge_graph_object = KnowledgeGraph(vAR_candidate_sentences)\n",
    "vAR_knowledge_graph_object.RUN_ALL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display top 10 relations\n",
    "df = pd.DataFrame(vAR_knowledge_graph_object.vAR_relations, columns=['cols'])\n",
    "df.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "relations = [\"is\", 'let', 'plays','Let', 'are', 'use']\n",
    "for i in relations:\n",
    "    print(\"Knowledge Graph for Relation :\",i)\n",
    "    vAR_knowledge_graph_object.plot_graph(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RKp_CLZCInA"
   },
   "source": [
    "# Copyright Notice:\n",
    "\n",
    "Local and international copyright laws protect\n",
    "this material. Repurposing or reproducing\n",
    "this material without written approval from\n",
    "DeepSphere.AI violates the law.\n",
    "\n",
    "(c) DeepSphere.AI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HBl5TBxtCT7Y",
    "o2alyw5z3VnZ",
    "ABzLWUmj3NUZ",
    "O2F_uuBZ73SP",
    "Y6OX7eIw3dBR",
    "jliAIav58vn4",
    "wCdPvCW_3ysE",
    "0RyEZB2x4OMH",
    "NxWAlyDx4RvQ",
    "C2hFLcyG7naO",
    "Sv5rq2V3GSF6",
    "KIXVpD3J7unX",
    "3RKp_CLZCInA"
   ],
   "name": "Knowledge graph.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
